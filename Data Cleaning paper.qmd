---
title: "Data Cleaning Paper"
format: html
editor: visual
Author: Fernando Yeung
Class: OMSBA-5300
---

## Data_Exploration_Assignment

### **Step 1: Data Aggregation and Preprocessing**

```{r}
library(tidyverse)
library(dplyr)
library(rio)
library(lubridate)

# Aggregating Google Tends data

trends_files <- list.files( path = "C:/Users/ferna/OneDrive/Documents/OMSBA 5300/Data explaration/OMSBA-5300/Lab3_Rawdata",
                            pattern = "^trends_up_to.*\\.csv$",
                            full.names = TRUE)

#Bind the files into a single data set
google_trends_data <- import_list(trends_files, rbind = TRUE)

# Extract first ten characters from monthorweek

google_trends_data$monthorweek <- as.Date(ymd(str_sub(google_trends_data$monthorweek, 1, 10)))

# Aggregate to months using floor_date
google_trends_data$month <- floor_date(google_trends_data$monthorweek, unit = "month")

# Standardize the index variable within each school and keyword
google_trends_data <- google_trends_data %>%
  group_by(schname, keynum) %>%
  mutate(std_index = (index - mean(index, na.rm = TRUE)) / sd(index, na.rm = TRUE)) %>%
  ungroup()

# aggregate to the school-month level
school_data <- google_trends_data %>%
  group_by(schname, month) %>%
  summarize(mean_std_index = mean(std_index, na.rm = TRUE))

# Print the first few rows of the aggregated data
head(school_data)

# adding Score card data
scorecard_data <- read_csv("C:/Users/ferna/OneDrive/Documents/OMSBA 5300/Data explaration/OMSBA-5300/Lab3_Rawdata/Most+Recent+Cohorts+(Scorecard+Elements).csv")

# reading in id_name_link data
name_data <- import("C:/Users/ferna/OneDrive/Documents/OMSBA 5300/Data explaration/OMSBA-5300/Lab3_Rawdata/id_name_link.csv")

schools <- name_data %>%
  group_by(schname) %>%
  mutate(n = n()) %>%
  ungroup()

# Filter out schools that show up more than once
filtered_name_data <- schools %>%
  filter(n == 1) %>%
  select(schname, unitid, opeid)

final_data <- school_data %>%
  inner_join(filtered_name_data, by = "schname") %>%
  inner_join(scorecard_data, by = c("unitid" = "UNITID", "opeid" = "OPEID")) %>% 
  filter(PREDDEG == 3) %>% 
  rename("average_earnings" = "md_earn_wne_p10-REPORTED-EARNINGS")
```

In this step, I'm aggregating Google Trends data and standardizing the index variable within each school and keyword. Then, I'm aggregating the data to the school-month level and adding Scorecard data.

### **Step 2: Creating Binary Variables**

```{r}
#create a threshold to find the median earnings
threshold <- median(final_data$average_earnings)
  #median earnings is 42300

#create a binary variable for high/low earning
final_data$HighEarning <- ifelse(final_data$average_earnings >= threshold, 1, 0)

#create date value for date
release_date <- as.Date("2015-09-01")

#binary value for date
final_data$PostScorecard <- ifelse(final_data$month >= release_date, 1, 0)

#SAT median for college
sat_average <- median(final_data$SAT_AVG_ALL)

final_data$SATMScore <- ifelse(final_data$SAT_AVG_ALL >= sat_average, 1,  0)
```

In step 2, I'm creating binary values so for my regressions I can see the before and after the release of the article to see if there was any correlation between.

### **Step 3: Regressions and Graphs**

```{r}
library(fixest)
google_search <- feols(mean_std_index ~ HighEarning, data = final_data)
etable(google_search)
summary(google_search)

#after the release
google_search_after <- feols(mean_std_index ~ HighEarning + PostScorecard, data = final_data)
etable(google_search)

#regression taking SAT average scores
google_SAT <- feols(mean_std_index ~ HighEarning + SATMScore, data = final_data)
etable(google_SAT)

#after release 
google_SAT_after <- feols(mean_std_index ~ HighEarning + PostScorecard  + SATMScore, data = final_data)
etable(google_SAT_after)

```

For my regressions I have decided that I would do straight forward relationship between the mean_index and high earning to see if there was any relationship between the earnings and Google search this was before the article was released. and did the same thing for after the release, I also wanted to see if the average SAT score would change anything so I made a regression that would show me that.

### **Step 4: Creating new data frame for after 2015**

```{r}
# Print the first few rows of the final data
head(final_data)

final_data_release <- school_data %>%
  inner_join(filtered_name_data, by = "schname") %>%
  inner_join(scorecard_data, by = c("unitid" = "UNITID", "opeid" = "OPEID")) %>% 
  filter(PREDDEG == 3) %>% 
  filter(month >= as.Date("2015-09-01")) %>% 
  rename("average_earnings" = "md_earn_wne_p10-REPORTED-EARNINGS")

threshold_release <- median(final_data_release$average_earnings)

final_data_release$HighEarningRelease <- ifelse(final_data_release$average_earnings >= threshold, 1, 0)
```

Step 4 I had to make a new data frame and binary values to see if there was a difference after the article was posted.

### **Analysis of the data**

```{r}
google_search <- feols(mean_std_index ~ HighEarning, data = final_data)
etable(google_search)
summary(google_search)

#after the release
google_search_after <- feols(mean_std_index ~ HighEarning + PostScorecard, data = final_data)
etable(google_search_after)
summary(google_search_after)

#regression taking SAT average scores
google_SAT <- feols(mean_std_index ~ HighEarning + SATMScore, data = final_data)
etable(google_SAT)

#after release 
google_SAT_after <- feols(mean_std_index ~ HighEarning + PostScorecard  + SATMScore, data = final_data)
etable(google_SAT_after)
```

In the google_search model, the constant term indicates a mean *mean_std_index* estimate of 0.0044, with a non-significant coefficient for highEarning at 0.0047. These estimations are based on 56,944 observations, yielding exceedingly low R-squared and adjusted R-squared values of approximately 1.59e-5 and -1.64e-6.

In the *google_search_after* model, the constant term suggests a substantial increase in mean_std_index post-Scorecard release, with a statistically significant estimate of 0.0562. While the coefficient for HighEarning remains statistically insignificant at 0.0046, the inclusion of PostScoredcard reveals a notable decrease in *mean_std_index* post-release, statistically significant at -0.2712. The R-squared value stands at approximately 0.0326.

### **Graphs for the regressions**

```{r}
ggplot(final_data, aes(x = average_earnings , y = mean_std_index, color = factor(HighEarning))) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE, color = "blue") +  
  labs(title = "Regression of mean_std_index on HighEarning",
       x = "HighEarning",
       y = "mean_std_index")+
  scale_color_manual(values = c("red", "blue"),labels = c("Low Earnings", "High Earnings")) +
  theme_minimal()

#graph after the release of the article
ggplot(final_data_release, aes(x = average_earnings , y = mean_std_index, color = factor(HighEarningRelease))) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE, color = "blue") +  
  labs(title = "Regression of mean_std_index on HighEarning",
       x = "HighEarning",
       y = "mean_std_index")+
  scale_color_manual(values = c("red", "blue"),labels = c("Low Earnings", "High Earnings")) +
  theme_minimal()

#graph for SAT
ggplot(final_data, aes(x = average_earnings , y = mean_std_index, color = factor(SATMScore))) +
  geom_point() +  # scatter plot of observed data
  geom_smooth(method = "lm", se = FALSE, color = "blue") +  # fitted regression line
  labs(title = "Regression of mean_std_index on HighEarning",
       x = "HighEarning",
       y = "mean_std_index")+
  scale_color_manual(values = c("red", "blue"),labels = c("Low Score", "High Score")) +
  theme_minimal()
```

I analyzed the correlation between median income and an index among individuals who graduated ten years ago. Initially, the graph indicated no significant difference in the correlation between high and low income groups. After accounting for the article's release, the regression analysis yielded a similar result, with the graph depicting an even split between the two groups. Additionally, when examining the correlation between median income and SAT scores, the graph showed no discernible correlation whatsoever.

### **Research Question**

The College Scorecard was released at the start of September 2015. **Among colleges that predominantly grant bachelor’s degrees**, did the release of the Scorecard shift student interest to high-earnings colleges relative to low-earnings ones (as proxied by Google searches for keywords associated with those colleges)?

The introduction of the College Scorecard (increased/decreased) search activity on Google Trends for colleges with high-earning graduates by 0.2712 (specific number and units) relative to what it did for colleges with low-earning graduates, with a standard error of 0.0062 . This result comes from the scoredcard coefficient(s) in my regression.

Based on the data and analysis, the release of the College Scorecard in September 2015 did not lead to a significant shift in student interest toward high-earning colleges relative to low-earning ones, this was assumption can be made from the data google provided.

In my opinion, I agree that the College Scorecard release in September 2015 didn't change how much students are interested in high-earning colleges compared to low-earning ones, as shown by Google searches. There are many reasons for this. People care more about factors like school reputation (like Ivy League status), if the college offers the program they want, the campus vibe, location, alumni connections, and advice from parents. All these factors play a big role in choosing the right college, showing that the decision is about more than just potential earnings.
